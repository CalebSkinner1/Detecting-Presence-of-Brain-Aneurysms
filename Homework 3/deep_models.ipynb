{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca52ed03-44e5-48bc-ab1c-67e6803dbd05",
   "metadata": {},
   "source": [
    "# Deep neural nets for object recognition\n",
    "In this exercise, you will first develop a fully connected neural net model and test it on the CIFAR-10 problem. Then, you will build a convolutional neural net model and test it on the same CIFAR-10 problem. The purpose of this part of the exercise is to give you a working understanding of neural net models and give you experience in tuning their (many) hyper-parameters.\n",
    "\n",
    "Then, you will use a Resnet model pretrained on Imagenet and test its out-of-the-box performance on CIFAR-10. You will finetune the pretrained Resnet model on CIFAR-10 and test its performance on a set aside test set. Finally, you will use data augmentation and finetune the pretrained Resnet model with augmented data, and check its performance on a set aside test set.\n",
    "\n",
    "You will then comment on performance differences between fully connected networks and CNNs trained from scratch on CIFAR-10, relative to the performance you saw with linear models (softmax, GDA and SVM). You will also comment on the use of finetuning pre-trained models and the role of data augmentation fine tuning large parameter models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64e240-4d84-408e-98a1-b4809f854366",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378bfaf-c22f-42ff-8ef6-dc55dc531a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchview import draw_graph\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc9b25-c05e-4c46-9b53-4061787b6f8a",
   "metadata": {},
   "source": [
    "# The CIFAR10 dataset\n",
    "- Download and normalize the CIFAR10 dataset from torchvision\n",
    "- Split the CIFAR10 data into train, validation and test set\n",
    "- Set the batch size for processing these datasets\n",
    "- Build the dataloaders for train, validation, and test set which will be used in the training loop\n",
    "- Define the string class labels (targets are numeric 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0cf4f-273b-412d-81b9-88eeb0d6df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std for the RGB channels in CIFAR10\n",
    "tmean = [0.49139968, 0.48215841, 0.44653091]\n",
    "tstd = [0.24703223, 0.24348513, 0.26158784]\n",
    "\n",
    "# Image size\n",
    "img_size=224\n",
    "\n",
    "# transform the 32x32x3 images into a tensor after normalizing\n",
    "# each channel using the parameters above\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(tmean, tstd)])\n",
    "\n",
    "# download and transform the  trainset and testset for training\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
    "\n",
    "torch.manual_seed(42)  # for reproducibility\n",
    "\n",
    "#split trainset into a train and a val set (90-10 split)\n",
    "lengths = [int(p * len(trainset)) for p in [0.9,0.1]]\n",
    "tr,v = torch.utils.data.random_split(trainset,lengths)\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(tr.indices)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(v.indices)\n",
    "\n",
    "# set batch size and set up the data generators for train, val, test sets\n",
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,sampler=train_sampler)\n",
    "valloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,sampler=val_sampler)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size)\n",
    "\n",
    "print(\"Number of training batches = \",len(trainloader))\n",
    "print(\"Number of validation batches = \",len(valloader))\n",
    "print(\"Number of test batches = \",len(testloader))\n",
    "\n",
    "# define the output classes\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce532cb-c6e0-4990-ab7f-6724b85b0a0c",
   "metadata": {},
   "source": [
    "# Visualize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753fa24c-9723-4939-b22f-68d9a93c88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,ytr = next(iter(trainloader))\n",
    "# make a 8x8 grid and display 64 images from the first batch of training data\n",
    "rows,cols = 8,8\n",
    "fig = plt.figure(figsize=(8,8),constrained_layout=True)\n",
    "\n",
    "for i in range(0,rows*cols):\n",
    "    fig.add_subplot(rows,cols,i+1)\n",
    "    tmp = np.transpose(Xtr[i].numpy(),(1,2,0))\n",
    "    plt.imshow(((tmp*tstd + tmean)*255).astype(np.uint8))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(classes[ytr[i].numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb3bad-f6a7-4f70-8e82-938cfac1b4d6",
   "metadata": {},
   "source": [
    "# A five layer fully connected (FC) feedforward network (20 points)\n",
    "- has an input layer, two hidden layers, and an output layer\n",
    "- complete the function definitions below\n",
    "- you will find d2l.ai Chapters 5.2, 5.6, 6.1, 6.2, 6.3 very useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9dc864-1922-406d-ab8f-80f6591f2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiveLayerFC(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes,lr,wd):\n",
    "        super().__init__()\n",
    "        # set up learning rate lr and weight decay wd\n",
    "        # set up the network structure using nn.Sequential\n",
    "        # use the ReLU non-linearity after all the hidden layers\n",
    "        # use Xavier normal initialization for the weights in the hidden layers\n",
    "        # use zero initialization for the bias weights\n",
    "        # do not forget to Flatten the input before passing it to the first hidden layer\n",
    "        ######## START YOUR CODE HERE (7-10 lines)\n",
    "\n",
    "        \n",
    "        ######## END YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward propagate the input x through the network\n",
    "        # output should be a vector of dimension 10\n",
    "        ######## START YOUR CODE HERE (1 line)\n",
    "        \n",
    "\n",
    "        ######## END YOUR CODE HERE\n",
    "\n",
    "    def loss(self,yhat,y,averaged=True):\n",
    "        # use nn.functional.cross_entropy() to evaluate loss with prediction (yhat)\n",
    "        # and truth (y). Average it over a batch.\n",
    "        ######### START YOUR CODE HERE (1-2 lines)\n",
    "        \n",
    "\n",
    "        ######### END YOUR CODE HERE\n",
    "\n",
    "    def predict(self,x):\n",
    "       # propagate x forward and return the index of the\n",
    "       # the highest valued output component\n",
    "       ######## START YOUR CODE HERE (1 line)\n",
    "       \n",
    "\n",
    "       ######### END YOUR CODE HERE\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # set up the Adam optimizer with learning rate and weight decay specified\n",
    "        # in the model object\n",
    "        ######## START YOUR CODE HERE (1 line)\n",
    "        \n",
    "\n",
    "\n",
    "        ######### END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e73bf-9f14-44c1-a9f6-f26f9bee0bbd",
   "metadata": {},
   "source": [
    "# Test the FiveLayerFC class\n",
    "- set the device to GPU if you have access to it.\n",
    "- In Google Colab, you can select runtime, and pick the free T4 GPU choice.\n",
    "- to understand how GPU memory and CPU memory interact, read Section 6.7 of the d2l.ai textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a9a3e-a377-4ca9-bed2-a7398e36cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "wd = 1e-2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device is: ', device)\n",
    "\n",
    "def test_FiveLayerFC(lr,wd):\n",
    "    input_size = 32*32*3\n",
    "    x = torch.zeros((64, input_size), dtype=torch.float).to(device)  # minibatch size 64, feature dimension 50\n",
    "    model = FiveLayerFC(input_size, 100, 100,10,lr,wd).to(device)\n",
    "    outputs = model(x)\n",
    "    print(outputs.size())  # you should see [64, 10]\n",
    "    model_graph = draw_graph(\n",
    "        model,\n",
    "        input_size=x.shape,\n",
    "        expand_nested=True,\n",
    "        save_graph=True,\n",
    "        filename=\"my_Five_layer_FC_model\",\n",
    "        directory=\"./\"\n",
    "    )\n",
    "\n",
    "test_FiveLayerFC(lr,wd)\n",
    "\n",
    "# draw the model\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(mpimg.imread('my_Five_layer_FC_model.png'))\n",
    "plt.axis('off') # Turn off axis numbers and ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414a0d3-0c25-43e6-83a6-20d008878f5d",
   "metadata": {},
   "source": [
    "# Checking the network setup (15 points)\n",
    "As a sanity check, make sure you can overfit a small dataset of 64 images. We will use a five-layer network with 100 units in the two hidden layers. You will need to tweak the learning rate and weight decay, but you should be able to overfit and achieve 100% training accuracy within 20 epochs. We have given you parameter choices that work. You should report on at least another choice of learning rate and weight decay that allows you to fit the training data to 100% accuracy within 20 epochs.\n",
    "\n",
    "Complete the function train_model_small that takes a single batch (Xtr,ytr) of 64 images and their labels for training, and a single batch (Xval,yval) of validation images and trains an initialized model for num_epochs epochs.\n",
    "\n",
    "- Initialize train_loss and val_loss (which will hold training and validation set loss for each epoch)\n",
    "- Configure optimizer for the model\n",
    "- for epoch in range(num_epochs)\n",
    "    - zero out gradients in the optimizer\n",
    "    - compute output of network by forward propagating Xtr through network\n",
    "    - compute loss using output and ytr\n",
    "    - backpropagate the loss\n",
    "    - store the training loss for this epoch\n",
    "    - compute validation set loss for this epoch (remember to turn off gradient update with torch.no_grad())\n",
    "- return model, train_loss and val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79932295-b287-4b95-98b2-58bcea655a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,ytr = next(iter(trainloader))\n",
    "Xval, yval = next(iter(valloader))\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-2\n",
    "wd = 1e-3\n",
    "\n",
    "def train_model_small(model,Xtr,ytr,Xval,yval,num_epochs):\n",
    "\n",
    "    ####### START YOUR CODE HERE (10-14 lines)\n",
    "    \n",
    "    ######## END YOUR CODE HERE\n",
    "\n",
    "    return model,train_loss,val_loss\n",
    "\n",
    "model = FiveLayerFC(32*32*3,100,100,10,lr,wd)\n",
    "model,train_loss,val_loss = train_model_small(model,Xtr,ytr,Xval,yval,num_epochs)\n",
    "torch.save(model.state_dict(), 'model_small.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e6fd5c-809f-4e46-b8ef-3fa0d8a4804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(num_epochs,train_loss,val_loss):\n",
    "   plt.plot(torch.arange(num_epochs),train_loss, label=\"train_loss\")\n",
    "   plt.plot(torch.arange(num_epochs),val_loss, label=\"val_loss\")\n",
    "   plt.title(\"Training and Validation Loss Curves\")\n",
    "   plt.xlabel(\"Epoch\")\n",
    "   plt.ylabel(\"Loss\")\n",
    "   plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da1340-848e-434f-b8b0-2296eab551ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve for the small model training\n",
    "\n",
    "plot_loss_curves(num_epochs,train_loss,val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e6b18-ce4a-456a-8e0f-d8c42e44cef2",
   "metadata": {},
   "source": [
    "# Test your model on the training set\n",
    "- you should get 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98ed10-ef2e-4961-873b-87ca60d255be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ypred = model.predict(Xtr)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(ytr,ypred)\n",
    "    acc = sklearn.metrics.accuracy_score(ytr,ypred)\n",
    "    print('Accuracy on test set = ',acc)\n",
    "    print(cm)\n",
    "    print(sklearn.metrics.classification_report(ytr,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5ebbc-b654-4586-902f-d1d6e13ede95",
   "metadata": {},
   "source": [
    "# Train the full model (25 points)\n",
    "- Initialize train_loss and val_loss (which will hold training and validation set loss for each epoch)\n",
    "- Configure optimizer for the model\n",
    "- for epoch in range(num_epochs)\n",
    "    - for each batch (Xtr,ytr) in training set\n",
    "       - zero out gradients in the optimizer\n",
    "       - compute output of network by forward propagating Xtr through network\n",
    "       - compute loss using output and ytr\n",
    "       - backpropagate the loss\n",
    "       - update the parameters with .step() on optimizer\n",
    "       - accumulate the training loss for this batch\n",
    "    - store training loss for this epoch\n",
    "    - compute validation set loss for this epoch (remember to turn off gradient update with torch.no_grad()) and remember to iterate over all the batches of the validation set\n",
    "    \n",
    "- return model, train_loss and val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d83643-8bb3-4680-bced-27be39c5f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,trainloader,valloader,num_epochs):\n",
    "    ######## START YOUR CODE HERE (20-24 lines)\n",
    "    \n",
    "    ######## END YOUR CODE HERE\n",
    "    return model,train_loss,val_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5372bb92-39f3-4041-b507-e7400aec4289",
   "metadata": {},
   "source": [
    "# Train and test performance of model\n",
    "- hyperparameter choice: lr = 1e-5, weight_decay = 1e-2\n",
    "- train the model using training and validation data\n",
    "- get accuracy, confusion matrix and classification report on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91464fa6-9fd4-4809-98fd-2cc271993ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a model with a testloader\n",
    "# return an array of test images, true labels, predicted labels\n",
    "\n",
    "def model_eval(model,testloader):\n",
    "    X_test_list = [] # Use a list to store batches of test data\n",
    "    with torch.no_grad():\n",
    "        ys=[]\n",
    "        outputs=[]\n",
    "        for i, tdata in enumerate(testloader):\n",
    "            tX,ty = tdata\n",
    "            tX=tX.to(device)\n",
    "            X_test_list.append(tX.detach().cpu().numpy())\n",
    "            ty=ty.to(device)\n",
    "            output = model.predict(tX)\n",
    "            ys.append(ty.detach().cpu().numpy())\n",
    "            outputs.append(output.detach().cpu().numpy())\n",
    "\n",
    "    X_test = np.concatenate(X_test_list)\n",
    "    ys=np.hstack(ys)\n",
    "    outputs= np.hstack(outputs)\n",
    "    cm = sklearn.metrics.confusion_matrix(ys,outputs)\n",
    "    print(\"****************************************************************************************\")\n",
    "    print(\"performance report\")\n",
    "    print(sklearn.metrics.classification_report(ys,outputs))\n",
    "    print(\"confusion matrix:\")\n",
    "    disp = sklearn.metrics.ConfusionMatrixDisplay(cm,display_labels=classes)\n",
    "    disp.plot()\n",
    "    return X_test,ys,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6abac-becb-475d-8b83-24820bd4af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "wd = 1e-2\n",
    "num_epochs = 20\n",
    "\n",
    "model_mlp = FiveLayerFC(32*32*3,200,200,10,lr,wd).to(device)\n",
    "model_mlp,train_loss,val_loss = train_model(model_mlp,trainloader,valloader,num_epochs)\n",
    "torch.save(model_mlp.state_dict(), 'model_mlp.pth')\n",
    "\n",
    "plot_loss_curves(num_epochs,train_loss,val_loss)\n",
    "X_test, ys, outputs = model_eval(model,testloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4459077-cdf4-423e-acb8-13eafcdf2447",
   "metadata": {},
   "source": [
    "# Visualization of confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303d747-99b7-447a-bb0f-c6a4ad4c6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some plot utilities\n",
    "\n",
    "def denormalize(img):\n",
    "    \"\"\"Undo CIFAR-10 normalization and convert to uint8 for imshow.\"\"\"\n",
    "    img = np.transpose(img, (1, 2, 0))           # CHW -> HWC\n",
    "    img = (img * tstd + tmean) * 255.0\n",
    "    return np.clip(img, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Only use this for models in augmented data\n",
    "def plot_confused_classes_aug(model, testloader, classes, cl_a, cl_b):\n",
    "    X_aa_list = []\n",
    "    X_ab_list = []\n",
    "    X_ba_list = []\n",
    "    X_bb_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            yhat = model(X)\n",
    "            y_pred = torch.argmax(yhat, dim=1).to(device)\n",
    "\n",
    "            # Filter images based on true and predicted labels\n",
    "            X_aa_batch = X[(y == cl_a) & (y_pred == cl_a)]\n",
    "            X_ab_batch = X[(y == cl_a) & (y_pred == cl_b)]\n",
    "            X_ba_batch = X[(y == cl_b) & (y_pred == cl_a)]\n",
    "            X_bb_batch = X[(y == cl_b) & (y_pred == cl_b)]\n",
    "\n",
    "            X_aa_list.append(X_aa_batch.detach().cpu().numpy())\n",
    "            X_ab_list.append(X_ab_batch.detach().cpu().numpy())\n",
    "            X_ba_list.append(X_ba_batch.detach().cpu().numpy())\n",
    "            X_bb_list.append(X_bb_batch.detach().cpu().numpy())\n",
    "\n",
    "    X_aa = np.concatenate(X_aa_list) if X_aa_list else np.array([])\n",
    "    X_ab = np.concatenate(X_ab_list) if X_ab_list else np.array([])\n",
    "    X_ba = np.concatenate(X_ba_list) if X_ba_list else np.array([])\n",
    "    X_bb = np.concatenate(X_bb_list) if X_bb_list else np.array([])\n",
    "\n",
    "    size = 5   # grid size inside each confusion block\n",
    "    pad = 0.5  # spacing between quadrants\n",
    "    total = 2 * size + pad  # logical grid size\n",
    "\n",
    "    fig = plt.figure(figsize=(size*2, size*2))\n",
    "\n",
    "    # Loop through quadrants\n",
    "    for images, (true_row, pred_col) in [\n",
    "        (X_aa, (0, 0)),  # true A, pred A\n",
    "        (X_ab, (0, 1)),  # true A, pred B\n",
    "        (X_ba, (1, 0)),  # true B, pred A\n",
    "        (X_bb, (1, 1)),  # true B, pred B\n",
    "    ]:\n",
    "        for idx, image_data in enumerate(images[:size*size]):\n",
    "            # Grid position in \"data units\"\n",
    "            x = idx % size + pred_col * (size + pad)\n",
    "            y = idx // size + true_row * (size + pad)\n",
    "\n",
    "            # Normalize to figure coords [0,1]\n",
    "            ax = fig.add_axes([x / total,\n",
    "                               y / total,\n",
    "                               1 / total,\n",
    "                               1 / total])\n",
    "\n",
    "            img = denormalize(image_data)\n",
    "            ax.imshow(img)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    # Add invisible overlay axis (in figure space)\n",
    "    ax_main = fig.add_axes([0, 0, 1, 1], frameon=False)\n",
    "    ax_main.set_xticks([ (size/2)/total, (size+pad+size/2)/total ])\n",
    "    ax_main.set_xticklabels([classes[cl_a], classes[cl_b]], fontsize=12)\n",
    "\n",
    "    ax_main.set_yticks([ (size/2)/total, (size+pad+size/2)/total ])\n",
    "    ax_main.set_yticklabels([classes[cl_a], classes[cl_b]], fontsize=12)\n",
    "\n",
    "    ax_main.set_xlabel(\"Predicted label\", fontsize=14)\n",
    "    ax_main.set_ylabel(\"True label\", fontsize=14)\n",
    "\n",
    "    # Hide tick marks and spines\n",
    "    ax_main.tick_params(axis='both', which='both', length=0)\n",
    "    for spine in ax_main.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    # Divider lines in normalized coords\n",
    "    ax_main.plot([ (size+pad/2)/total, (size+pad/2)/total ], [0,1], \"k:\")\n",
    "    ax_main.plot([0,1], [ (size+pad/2)/total, (size+pad/2)/total ], \"k:\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# use this for regular models with no data augmentation\n",
    "def plot_confused_classes(X_test, all_y_true, all_y_pred, classes, cl_a, cl_b):\n",
    "    X_aa = X_test[(all_y_true == cl_a) & (all_y_pred == cl_a)]\n",
    "    X_ab = X_test[(all_y_true == cl_a) & (all_y_pred == cl_b)]\n",
    "    X_ba = X_test[(all_y_true == cl_b) & (all_y_pred == cl_a)]\n",
    "    X_bb = X_test[(all_y_true == cl_b) & (all_y_pred == cl_b)]\n",
    "\n",
    "    size = 5   # grid size inside each confusion block\n",
    "    pad = 0.5  # spacing between quadrants\n",
    "    total = 2 * size + pad  # logical grid size\n",
    "\n",
    "    fig = plt.figure(figsize=(size*2, size*2))\n",
    "\n",
    "    # Loop through quadrants\n",
    "    for images, (true_row, pred_col) in [\n",
    "        (X_aa, (0, 0)),  # true A, pred A\n",
    "        (X_ab, (0, 1)),  # true A, pred B\n",
    "        (X_ba, (1, 0)),  # true B, pred A\n",
    "        (X_bb, (1, 1)),  # true B, pred B\n",
    "    ]:\n",
    "        for idx, image_data in enumerate(images[:size*size]):\n",
    "            # Grid position in \"data units\"\n",
    "            x = idx % size + pred_col * (size + pad)\n",
    "            y = idx // size + true_row * (size + pad)\n",
    "\n",
    "            # Normalize to figure coords [0,1]\n",
    "            ax = fig.add_axes([x / total,\n",
    "                               y / total,\n",
    "                               1 / total,\n",
    "                               1 / total])\n",
    "\n",
    "            img = denormalize(image_data)\n",
    "            ax.imshow(img)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "       # Add invisible overlay axis (in figure space)\n",
    "    ax_main = fig.add_axes([0, 0, 1, 1], frameon=False)\n",
    "    ax_main.set_xticks([ (size/2)/total, (size+pad+size/2)/total ])\n",
    "    ax_main.set_xticklabels([classes[cl_a], classes[cl_b]], fontsize=12)\n",
    "\n",
    "    ax_main.set_yticks([ (size/2)/total, (size+pad+size/2)/total ])\n",
    "    ax_main.set_yticklabels([classes[cl_a], classes[cl_b]], fontsize=12)\n",
    "\n",
    "    ax_main.set_xlabel(\"Predicted label\", fontsize=14)\n",
    "    ax_main.set_ylabel(\"True label\", fontsize=14)\n",
    "\n",
    "    # Hide tick marks and spines\n",
    "    ax_main.tick_params(axis='both', which='both', length=0)\n",
    "    for spine in ax_main.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    # Divider lines in normalized coords\n",
    "    ax_main.plot([ (size+pad/2)/total, (size+pad/2)/total ], [0,1], \"k:\")\n",
    "    ax_main.plot([0,1], [ (size+pad/2)/total, (size+pad/2)/total ], \"k:\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee78f7dc-8490-4246-80b2-94733df9b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function below to see the visualized confusion matrix (cats vs dogs) for model_mlp\n",
    "\n",
    "# Change based on your observation of the confusion matrices\n",
    "# For example, from the confusion matrix of model1, classes 3 (cat) and 5 (dog) seem to be confused.\n",
    "\n",
    "cl_a, cl_b = 3, 5 # Integer class labels\n",
    "plot_confused_classes(X_test, ys, outputs, classes, cl_a, cl_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30fbe4-8e39-472a-b368-2554439c7d4a",
   "metadata": {},
   "source": [
    "# Convolutional network (15 points)\n",
    "- complete the class definition below\n",
    "- The network structure is provided. Feel free to modify it -- in which case, rename the class, and run the experiments below.\n",
    "- The network structure is a sequence of three Conv2d, ReLU, Conv2D, ReLU, MaxPool2d, BatchNorm2d blocks.\n",
    "- The final layers include two fully connected layers and an output layer with 10 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260616a2-7742-47bd-bfd1-752955824c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    def __init__(self,lr,wd):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.wd = wd\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # forward propagate x through network\n",
    "        ######## START YOUR CODE HERE (1 line)\n",
    "        \n",
    "        ######## END YOUR CODE HERE\n",
    "\n",
    "    def loss(self,yhat,y,averaged=True):\n",
    "        # compute cross-entropy loss between network output and true labels y\n",
    "        # averaged over a batch\n",
    "        ######## START YOUR CODE HERE (1-2 lines)\n",
    "        \n",
    "        ######## END YOUR CODE HERE\n",
    "\n",
    "    def predict(self,X):\n",
    "        # return the index of the highest output in the output layer\n",
    "        ######## START YOUR CODE HERE (1 line)\n",
    "        \n",
    "        ######## END YOUR CODE HERE\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # set up the Adam optimizer with default parameters and\n",
    "        # model's learning rate and weight decay\n",
    "        ######## START YOUR CODE HERE (1 line)\n",
    "        \n",
    "        ######## END YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e36db-f8fd-4ba7-ba2c-a3c5aa3a0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model\n",
    "\n",
    "lr = 1e-4\n",
    "wd = 1e-1\n",
    "model_cnn = ConvModel(lr,wd).to(device)\n",
    "\n",
    "cnn_model_graph = draw_graph(\n",
    "        model_cnn,\n",
    "        input_size=(1,3,32,32),\n",
    "        expand_nested=True,\n",
    "        save_graph=True,\n",
    "        filename=\"my_CNN_model\",\n",
    "        directory=\"./\"\n",
    "    )\n",
    "\n",
    "# draw the model\n",
    "plt.figure(figsize=(20, 25))\n",
    "plt.imshow(mpimg.imread('my_CNN_model.png'))\n",
    "plt.axis('off') # Turn off axis numbers and ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804f3ac-19bd-4392-bb1f-3b1972d91bc1",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "- under two sets of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e04b8-52b1-41b5-ae89-bf9e34c33775",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "wd = 1e-1\n",
    "num_epochs = 30\n",
    "\n",
    "model_cnn = ConvModel(lr,wd).to(device)\n",
    "model_cnn,train_loss,val_loss = train_model(model_cnn,trainloader,valloader,num_epochs)\n",
    "torch.save(model_cnn.state_dict(), 'model_cnn.pth')\n",
    "\n",
    "# plot the validation and training loss curves\n",
    "plot_loss_curves(num_epochs,train_loss,val_loss)\n",
    "\n",
    "# run the trained model on test data and report\n",
    "# accuracy, confusion matrix and classification report\n",
    "\n",
    "X_test,ys,outputs = model_eval(model_cnn,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e1235-3bb8-490f-815b-2086f737f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual confusion matrix\n",
    "# Change based on your observation of the confusion matrices\n",
    "\n",
    "# For example, from the confusion matrix of model1, classes 3 (cat) and 5 (dog) seem to be confused.\n",
    "cl_a, cl_b = 3, 5 # Integer class labels\n",
    "\n",
    "plot_confused_classes(X_test, ys, outputs, classes,cl_a,cl_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76928106-8cc0-4d07-8e2f-1e4f82a332dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter set 2\n",
    "\n",
    "lr = 1e-3\n",
    "wd = 1e-3\n",
    "num_epochs = 20\n",
    "\n",
    "model_cnn2 = ConvModel(lr,wd).to(device)\n",
    "model_cnn2,train_loss,val_loss = train_model(model_cnn2,trainloader,valloader,num_epochs)\n",
    "torch.save(model_cnn2.state_dict(), 'model_cnn2.pth')\n",
    "\n",
    "# plot the validation and training loss curves\n",
    "plot_loss_curves(num_epochs,train_loss,val_loss)\n",
    "\n",
    "# run the trained model on test data and report\n",
    "# accuracy, confusion matrix and classification report\n",
    "\n",
    "X_test,ys,outputs = model_eval(model_cnn,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ddda9b-2693-4046-a2fa-540174aaa2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual confusion matrix\n",
    "# Change based on your observation of the confusion matrices\n",
    "\n",
    "# For example, from the confusion matrix of model1, classes 3 (cat) and 5 (dog) seem to be confused.\n",
    "cl_a, cl_b = 3, 5 # Integer class labels\n",
    "plot_confused_classes(X_test, ys, outputs, classes,cl_a,cl_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac8be2-847e-4bb9-b17b-bd1532c897ec",
   "metadata": {},
   "source": [
    "# Resnet18\n",
    "- Resnet18 is a common Deep Learning model with a CNN architecture. We can access pretrained weights of this model\n",
    "- The pretrained model is trained on Imagenet1k_V1 dataset.\n",
    "- Resnet18 expects 224x224x3 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008b6f5-f037-4068-8e04-b4ef354fdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# view the model\n",
    "model_graph = draw_graph(\n",
    "        resnet18,\n",
    "        input_size=(64, 3,32,32),  # Example: batch size 64, input features 3,32,32\n",
    "        expand_nested=True,  # Set to True to expand nested modules\n",
    "        save_graph=True,     # Set to True to save the graph automatically\n",
    "        filename=\"resnet18_graph\", # Desired filename for the saved graph\n",
    "        directory = \"./\",\n",
    "        device='cuda'         # Specify the device (e.g., 'cpu' or 'cuda')\n",
    "    )\n",
    "\n",
    "# draw the model\n",
    "plt.figure(figsize=(20, 60))\n",
    "plt.imshow(mpimg.imread('resnet18_graph.png'))\n",
    "plt.axis('off') # Turn off axis numbers and ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b76bfc7-9821-4150-b555-14511c2f0928",
   "metadata": {},
   "source": [
    "# Using pretrained Resnet18 to classify test images of CIFAR-10\n",
    "- Since the final layer of Resnet18 has 1000 units (Imagenet1K has 1000 outputs), we need to add a new fully connected layer that goes from 1000 Resnet18 outputs to the 10 ouputs that CIFAR-10 has.\n",
    "- We provide a function for evaluating the pretrained Resnet18 on the CIFAR-10 testloader\n",
    "-  It calculates confusion matrix, and provides a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8097c-9b37-4a58-b104-e66d177fbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure device is 'cuda' for this part\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device is: ', device)\n",
    "\n",
    "# Modify the final fully connected layer for 10 classes\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 10)\n",
    "resnet18.to(device)\n",
    "\n",
    "def model_eval_res(model,testloader):\n",
    "    model.eval()\n",
    "    X_test_list = [] # Use a list to store batches of test data\n",
    "    with torch.no_grad():\n",
    "        ys=[]\n",
    "        outputs=[]\n",
    "        for i, tdata in enumerate(testloader):\n",
    "            tX,ty = tdata\n",
    "            tX=tX.to(device)\n",
    "            X_test_list.append(tX.detach().cpu().numpy())\n",
    "            ty=ty.to(device)\n",
    "            output = model(tX)\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            ys.append(ty.detach().cpu().numpy())\n",
    "            outputs.append(output.detach().cpu().numpy())\n",
    "\n",
    "    X_test = np.concatenate(X_test_list)\n",
    "    ys=np.hstack(ys)\n",
    "    outputs= np.hstack(outputs)\n",
    "    cm = sklearn.metrics.confusion_matrix(ys,outputs)\n",
    "    print(\"****************************************************************************************\")\n",
    "    print(\"performance report\")\n",
    "    print(sklearn.metrics.classification_report(ys,outputs))\n",
    "    print(\"confusion matrix:\")\n",
    "    disp = sklearn.metrics.ConfusionMatrixDisplay(cm,display_labels=classes)\n",
    "    disp.plot()\n",
    "    return X_test,ys,outputs\n",
    "\n",
    "X_test,ys,outputs = model_eval_res(resnet18,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19d49f-96e4-45d2-b0d6-71ff0bb1f215",
   "metadata": {},
   "source": [
    "# Finetune Pretrained Resnet18 on CIFAR-10 (25 points)\n",
    "Load a pre-trained Resnet18 model initialized with weights from Imagenet1K. Then, \n",
    "add a fully connected layer at the end so final output will have 10 units.\n",
    " Set num_epochs. Define an optimizer (Adam with lr = 1e-3 and weight_decay=1e-3) (you can try other lr).\n",
    "Define the loss function (nn.CrossEntropyLoss()).\n",
    "\n",
    "Build the training loop\n",
    "- Initialize train_loss and val_loss (which will hold training and validation set loss for each epoch)\n",
    "\n",
    "\n",
    "\n",
    " - for epoch in range(num_epochs)\n",
    "    - for each batch (Xtr,ytr) in training set\n",
    "     - - move Xtr and ytr to cuda device with .to(device)\n",
    "       - zero out gradients in the optimizer\n",
    "       -  compute output of network by calling resnet18(Xtr)\n",
    "       -  compute loss using output and ytr\n",
    "       - backpropagate the loss\n",
    "       -  update the parameters (with .step() on optimizer)\n",
    "       -  accumulate the training loss for this batch\n",
    "    - store training loss for this epoch\n",
    "    - compute validation set loss for this epoch (remember to turn off gradient update with torch.no_grad()) and remember to iterate over all the batches of the validation set\n",
    "    \n",
    "- return model, train_loss and val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50b9bcc-c915-4c89-9a3b-94935d8728f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet18 model\n",
    "resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes in CIFAR-10\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "# set num_epochs\n",
    "num_epochs = 10\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(resnet18.parameters(), lr=1e-3, weight_decay=1e-3) # You can adjust the learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def resnet18_train(resnet18,optimizer,criterion,num_epochs,trainloader,valloader):\n",
    "    \n",
    "    # START YOUR CODE HERE (20-24 lines)\n",
    "\n",
    "    # END YOUR CODE HERE  \n",
    "    return resnet18, train_loss_resnet, val_loss_resnet\n",
    "    \n",
    "# Save the fine-tuned model\n",
    "torch.save(resnet18.state_dict(), 'resnet18_cifar10.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893552de-548a-4f83-8070-76456d31bd1d",
   "metadata": {},
   "source": [
    "# Evaluate performance of model tuned on CIFAR-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb013e6-46aa-4f6e-b74d-576aa5c6c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(num_epochs,train_loss_resnet,val_loss_resnet)\n",
    "\n",
    "X_test, ys, outputs = model_eval_res(resnet18,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925691c-4914-4e1e-859d-44c169acf697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For resnet model finetuned on cifar10\n",
    "\n",
    "# Change based on your observation of the confusion matrices\n",
    "# For example, from the confusion matrix of model1, classes 3 (cat) and 5 (dog) seem to be confused.\n",
    "cl_a, cl_b = 5, 3 # Integer class labels\n",
    "\n",
    "plot_confused_classes(X_test, ys, outputs, classes, cl_a, cl_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed0e969-d1e8-4105-a51c-4b1bff97a073",
   "metadata": {},
   "source": [
    "# Resnet training with data augmentation\n",
    "- data augmentation is tricky. We have already selected the transforms for the training set. Make alterations to this sequence with care.\n",
    "- For the test set, we resize the 32x32x3 images to 224x224x3 and normalize using the known tmean/tstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe86ba7-a7c6-4d05-af9c-730f956c79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set transforms\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.Resize(img_size),\n",
    "     transforms.RandomRotation(20),\n",
    "     transforms.RandomHorizontalFlip(0.1),\n",
    "     transforms.ColorJitter(brightness=0.1,contrast = 0.1 ,saturation =0.1 ),\n",
    "     transforms.RandomAdjustSharpness(sharpness_factor = 2, p = 0.1),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(tmean,tstd),\n",
    "     transforms.RandomErasing(p=0.75,scale=(0.02, 0.1),value=1.0, inplace=False)])\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.Resize(img_size),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(tmean,tstd)])\n",
    "\n",
    "# download and transform the  trainset and testset for training\n",
    "trainset_aug = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform_train)\n",
    "testset_aug = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform_test)\n",
    "\n",
    "#split trainset into a train and a val set (90-10 split)\n",
    "lengths_aug = [int(p * len(trainset_aug)) for p in [0.9,0.1]]\n",
    "tr_aug,v_aug = torch.utils.data.random_split(trainset_aug,lengths_aug)\n",
    "train_sampler_aug = torch.utils.data.SubsetRandomSampler(tr_aug.indices)\n",
    "val_sampler_aug = torch.utils.data.SubsetRandomSampler(v_aug.indices)\n",
    "\n",
    "# set batch size and set up the data generators for train, val, test sets\n",
    "batch_size = 64 # reduce batch size to 8, otherwise training time is quite long..\n",
    "trainloader_aug = torch.utils.data.DataLoader(trainset_aug,batch_size=batch_size,sampler=train_sampler_aug)\n",
    "valloader_aug = torch.utils.data.DataLoader(trainset_aug,batch_size=batch_size,sampler=val_sampler_aug)\n",
    "testloader_aug = torch.utils.data.DataLoader(testset_aug, batch_size=batch_size)\n",
    "\n",
    "print(\"Number of training batches = \",len(trainloader_aug))\n",
    "print(\"Number of validation batches = \",len(valloader_aug))\n",
    "print(\"Number of test batches = \",len(testloader_aug))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc132160-15a5-4de4-a476-6df27226dc9e",
   "metadata": {},
   "source": [
    "# Train resnet18 with augmented CIFAR-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d996c3a1-e21c-4254-8083-60b540e67511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet18 model\n",
    "resnet18_aug = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes in CIFAR-10\n",
    "num_ftrs = resnet18_aug.fc.in_features\n",
    "resnet18_aug.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "resnet18_aug = resnet18_aug.to(device)\n",
    "\n",
    "# set num_epochs\n",
    "num_epochs = 10 \n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.SGD(resnet18_aug.parameters(), lr=1e-3, momentum=0.9) # You can adjust the learning rate\n",
    "# add weight decay at 1e-3 for better results\n",
    "# Adam optimizer tends to overfit\n",
    "# trying to imitate https://www.kaggle.com/code/abdelrahmanhesham601/resnet-18-fine-tuning-on-cifar-10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model on augmented data\n",
    "resnet18_aug, train_loss_resnet, val_loss_resnet = resnet18_train(resnet18_aug,optimizer,criterion,num_epochs,\n",
    "                                                                  trainloader_aug,valloader_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbfdfa-9625-4f22-8758-201c5e4f99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To save memory, we rewrite the model_eval_res() and the corresponding plot_confused_classes()\n",
    "\"\"\"\n",
    "def model_eval_res(model, testloader):\n",
    "    with torch.no_grad():\n",
    "        ys = []\n",
    "        outputs = []\n",
    "        indices_list = []\n",
    "        batch_start = 0\n",
    "\n",
    "        for i, (tX, ty) in enumerate(testloader):\n",
    "            tX = tX.to(device)\n",
    "            ty = ty.to(device)\n",
    "\n",
    "            output = model(tX)\n",
    "            output = torch.argmax(output, dim=1)\n",
    "\n",
    "            # save labels and preds\n",
    "            ys.append(ty.detach().cpu().numpy())\n",
    "            outputs.append(output.detach().cpu().numpy())\n",
    "\n",
    "            # save the corresponding data indices\n",
    "            batch_size = len(ty)\n",
    "            batch_indices = list(range(batch_start, batch_start + batch_size))\n",
    "            indices_list.extend(batch_indices)\n",
    "            batch_start += batch_size\n",
    "\n",
    "    ys = np.hstack(ys)\n",
    "    outputs = np.hstack(outputs)\n",
    "    indices = np.array(indices_list)\n",
    "\n",
    "    # evaluate\n",
    "    cm = sklearn.metrics.confusion_matrix(ys, outputs)\n",
    "    print(\"****************************************************************************************\")\n",
    "    print(\"performance report\")\n",
    "    print(sklearn.metrics.classification_report(ys, outputs))\n",
    "    print(\"confusion matrix:\")\n",
    "    disp = sklearn.metrics.ConfusionMatrixDisplay(cm, display_labels=classes)\n",
    "    disp.plot()\n",
    "\n",
    "    return indices, ys, outputs  # return indices now rather than the raw data\n",
    "\n",
    "\n",
    "def plot_confused_classes(X_test_indices, target_dataset, all_y_true, all_y_pred, classes, cl_a, cl_b):\n",
    "    X_aa_indices = X_test_indices[(all_y_true == cl_a) & (all_y_pred == cl_a)]\n",
    "    X_ab_indices = X_test_indices[(all_y_true == cl_a) & (all_y_pred == cl_b)]\n",
    "    X_ba_indices = X_test_indices[(all_y_true == cl_b) & (all_y_pred == cl_a)]\n",
    "    X_bb_indices = X_test_indices[(all_y_true == cl_b) & (all_y_pred == cl_b)]\n",
    "\n",
    "    size = 5   # grid size inside each confusion block\n",
    "    pad = 0.5  # spacing between quadrants\n",
    "    total = 2 * size + pad  # logical grid size\n",
    "\n",
    "    fig = plt.figure(figsize=(size*2, size*2))\n",
    "\n",
    "    # Loop through quadrants\n",
    "    for test_indices, (true_row, pred_col) in [\n",
    "        (X_aa_indices, (0, 0)),  # true A, pred A\n",
    "        (X_ab_indices, (0, 1)),  # true A, pred B\n",
    "        (X_ba_indices, (1, 0)),  # true B, pred A\n",
    "        (X_bb_indices, (1, 1)),  # true B, pred B\n",
    "    ]:\n",
    "        images=[target_dataset[test_index][0].cpu().numpy() for test_index in test_indices]\n",
    "        for idx, image_data in enumerate(images[:size*size]):\n",
    "            # Grid position in \"data units\"\n",
    "            x = idx % size + pred_col * (size + pad)\n",
    "            y = idx // size + true_row * (size + pad)\n",
    "\n",
    "            # Normalize to figure coords [0,1]\n",
    "            ax = fig.add_axes([x / total,\n",
    "                               y / total,\n",
    "                               1 / total,\n",
    "                               1 / total])\n",
    "\n",
    "            img = denormalize(image_data)\n",
    "            ax.imshow(img)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "       # Add invisible overlay axis (in figure space)\n",
    "    ax_main = fig.add_axes([0, 0, 1, 1], frameon=False)\n",
    "    ax_main.set_xticks([ (size/2)/total, (size+pad+size/2)/total ])\n",
    "    ax_main.set_xticklabels([classes[cl_a], classes[cl_b]], fontsize=12)\n",
    "\n",
    "    ax_main.set_yticks([ (size/2)/total, (size+pad+size/2)/total ])\n",
    "    ax_main.set_yticklabels([classes[cl_a], classes[cl_b]], fontsize=12)\n",
    "\n",
    "    ax_main.set_xlabel(\"Predicted label\", fontsize=14)\n",
    "    ax_main.set_ylabel(\"True label\", fontsize=14)\n",
    "\n",
    "    # Hide tick marks and spines\n",
    "    ax_main.tick_params(axis='both', which='both', length=0)\n",
    "    for spine in ax_main.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    # Divider lines in normalized coords\n",
    "    ax_main.plot([ (size+pad/2)/total, (size+pad/2)/total ], [0,1], \"k:\")\n",
    "    ax_main.plot([0,1], [ (size+pad/2)/total, (size+pad/2)/total ], \"k:\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7dd1a-7cd4-409d-ad3f-7e08662d710e",
   "metadata": {},
   "source": [
    "# Evaluate the model trained on augmented CIFAR-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325d0c1-de93-42a3-bd15-bdfd009c0ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(num_epochs,train_loss_resnet,val_loss_resnet)\n",
    "\n",
    "X_test_indices, ys, outputs = model_eval_res(resnet18_aug,testloader_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22607568-04cc-40aa-bc1f-8ec29bce1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confused_classes(X_test_indices, testset_aug, ys, outputs, classes, cl_a, cl_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83666ee3-57be-4038-b335-613cff191ce2",
   "metadata": {},
   "source": [
    "# Comment (50 points) \n",
    "- performance difference between multilayer feedforward and convolutional neural nets\n",
    "- difference in the number of parameters between the two classes of deep models\n",
    "- impact of learning rate and weight decay choice on the feedforward networks\n",
    "- impact of learning rate and weight decay choice on convolutional networks\n",
    "- experiment with these two hyperparameters to achieve > 50% accuracy with feedforward networks, and > 80% accuracy with convolutional networks\n",
    "- explain out-of-the-box performance of Restnet18 with pretrained weights on CIFAR-10\n",
    "- explain the impact of tuning Resnet18 weights with CIFAR-10 data -- play with hyperparameters to get about 80% accuracy with this model\n",
    "- explain the impact of tuning Resnet18 weights with CIFAR-10 data -- you should be able to get about 94% accuracy with this model with the suggested hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8eb349-2246-4185-9bb7-753a56ea5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
