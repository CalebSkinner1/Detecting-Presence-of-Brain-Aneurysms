{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":34549.938258,"end_time":"2025-11-25T04:51:21.535048","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-24T19:15:31.596790","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"2878d3dd","cell_type":"code","source":"import sys\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.metrics import roc_auc_score\nimport h5py","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":16.211255,"end_time":"2025-11-24T19:15:51.324478","exception":false,"start_time":"2025-11-24T19:15:35.113223","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"211b2bcd","cell_type":"code","source":"ID_COL = 'SeriesInstanceUID'\n\nLABEL_COLS = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present',\n]\n\n# All tags (other than PixelData and SeriesInstanceUID) that may be in a test set dcm file\nDICOM_TAG_ALLOWLIST = [\n    'BitsAllocated',\n    'BitsStored',\n    'Columns',\n    'FrameOfReferenceUID',\n    'HighBit',\n    'ImageOrientationPatient',\n    'ImagePositionPatient',\n    'InstanceNumber',\n    'Modality',\n    'PatientID',\n    'PhotometricInterpretation',\n    'PixelRepresentation',\n    'PixelSpacing',\n    'PlanarConfiguration',\n    'RescaleIntercept',\n    'RescaleSlope',\n    'RescaleType',\n    'Rows',\n    'SOPClassUID',\n    'SOPInstanceUID',\n    'SamplesPerPixel',\n    'SliceThickness',\n    'SpacingBetweenSlices',\n    'StudyInstanceUID',\n    'TransferSyntaxUID',\n]","metadata":{"papermill":{"duration":0.011055,"end_time":"2025-11-24T19:15:51.340613","exception":false,"start_time":"2025-11-24T19:15:51.329558","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"6a98a084","cell_type":"code","source":"class MiniVolDataset(Dataset):\n    def __init__(self, h5_path, K=32, use_3d=True, return_id=False):\n        self.h5_path = h5_path\n        self.K = K\n        self.use_3d = use_3d\n        self.return_id = return_id\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        mini_index = []  # list of (subject_idx, slice_idx_array)\n\n        with h5py.File(h5_path, \"r\") as f:\n            z_len = f[\"z_len\"][:]  # (num_subjects,)\n            num_scans = len(z_len)\n\n            for s in range(num_scans):\n                Z = int(z_len[s])\n                if Z < K:\n                    continue  # this subject contributes no mini-vols\n\n                # all slice indices in physical order (from preprocessing)\n                avail = np.arange(Z, dtype=np.int16)\n\n                # repeatedly carve out K indices spread across 'avail'\n                while len(avail) >= K:\n                    n = len(avail)  # current number of remaining slices\n\n                    # positions in 0..n-1 roughly at quantiles:\n                    # floor((i+0.5) * n / K), i = 0,...,K-1\n                    pos = np.floor((np.arange(K) + 0.5) * n / K).astype(int)\n\n                    # get actual slice indices (already sorted because avail and pos are sorted)\n                    block = avail[pos]  # shape (K,)\n\n                    # record this mini-volume definition\n                    mini_index.append((s, block.copy()))\n\n                    # remove those positions from 'avail' so they won't be reused\n                    avail = np.delete(avail, pos)\n\n        self.mini_index = mini_index\n\n        # HDF5 handles opened lazily per worker\n        self._file = None\n        self._x_grp = None\n        self._y_ds = None          \n        self._yslice_grp = None    \n        self._uid_ds = None\n\n    def _ensure_open(self):\n        if self._file is None:\n            self._file = h5py.File(self.h5_path, \"r\")\n            self._x_grp = self._file[\"x\"]\n            self._y_ds = self._file[\"y\"]\n            self._yslice_grp = self._file[\"y_slice\"]\n            self._uid_ds = self._file.get(\"uid\", None)\n\n    def __len__(self):\n        return len(self.mini_index)\n\n    def __getitem__(self, idx):\n        self._ensure_open()\n\n        subj_idx, slice_idx = self.mini_index[idx] # slice_idx: (K,)\n\n        # load ONLY the K slices we need\n        dset = self._x_grp[str(subj_idx)]\n        mini = dset[slice_idx]\n\n        x = torch.from_numpy(mini)  # (K, 256, 256)\n        x = self.pool(x) # (K, 128, 128)\n\n        if self.use_3d:\n            x = x.unsqueeze(0) # (1, K, 128, 128)\n        x = x.float()\n\n        # per-slice labels -> y_where \n        y_slice_all = self._yslice_grp[str(subj_idx)] # (Z_s, 14)\n        y_slice_block = y_slice_all[slice_idx] # (K, 14)\n        y_block = y_slice_block.max(axis=0) # (14,)\n\n        where_np = y_block[:13]\n\n        # y_any from subject-level y_ds\n        subj_y_row = self._y_ds[subj_idx] # shape (14,)\n        any_np = subj_y_row[-1] # 'Aneurysm Present' column\n\n        y_where = torch.from_numpy(where_np.astype(\"float32\"))  # (13,)\n        y_any = torch.tensor(float(any_np), dtype=torch.float32)\n\n        if self.return_id:\n            return x, y_any, y_where, int(subj_idx)\n        else:\n            return x, y_any, y_where","metadata":{"papermill":{"duration":0.015899,"end_time":"2025-11-24T19:15:51.405592","exception":false,"start_time":"2025-11-24T19:15:51.389693","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"8b916258","cell_type":"code","source":"shard_dirs = [\n    \"fix-all-slices-shard-3\",\n    \"fix-all-slices-shard-2\",\n    \"fix-all-slices-shard-1\",\n    \"fix-all-slices-shard-4\",\n]\n\nshard_fnames = [\n    \"dataset_shard_3_all_slices.h5\",\n    \"dataset_shard_2_all_slices.h5\",\n    \"dataset_shard_1_all_slices.h5\",\n    \"dataset_shard_0_all_slices.h5\",\n]\n\nshard_paths = [\n    f\"/kaggle/input/{d}/{fn}\"\n    for d, fn in zip(shard_dirs, shard_fnames)\n]\n\nper_shard_ds = [\n    MiniVolDataset(\n        h5_path=path,\n        K=32,\n        use_3d=True, # channel dim specified \n        return_id=True, # gives subject index within that shard\n    )\n    for path in shard_paths\n]\n\nfull_dataset = ConcatDataset(per_shard_ds)","metadata":{"papermill":{"duration":0.44143,"end_time":"2025-11-24T19:15:51.851446","exception":false,"start_time":"2025-11-24T19:15:51.410016","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"a32b1b3c","cell_type":"code","source":"rng = np.random.default_rng(42)\n\nFRAC_SUBJ = 1.0  # use _% of subjects per shard \n\ntrain_subsets = []\nval_subsets = []\ntest_subsets  = []\n\ntrain_pos_subsets = []\nval_pos_subsets = []\n\nfor shard_id, ds in enumerate(per_shard_ds):\n    # all subject indices for this shard\n    subj_indices = np.array([s for (s, _) in ds.mini_index], dtype=int)\n    unique_subj = np.unique(subj_indices)\n\n    print(f\"Shard {shard_id}: {len(unique_subj)} subjects, {len(ds)} mini-volumes\")\n\n    ds._ensure_open()\n    y_all = ds._y_ds[:] # (num_subjects, 14) subject-level labels\n    any_pos_mask = (y_all[:, -1] == 1) # subject-level \"Aneurysm Present\"\n\n    # block-level positive mask using per-slice y_slice \n    block_has_pos = np.zeros(len(ds.mini_index), dtype=bool)\n    for i, (s, block) in enumerate(ds.mini_index):\n        y_slice_all = ds._yslice_grp[str(s)] # (Z_s, 14)\n        y_slice_block = y_slice_all[block] # (K, 14)\n        block_has_pos[i] = (y_slice_block[:, 13].max() == 1)\n\n    # ---------- SUBSAMPLE SUBJECTS HERE ----------\n    if FRAC_SUBJ < 1.0:\n        n_subj_total = len(unique_subj)\n        n_keep_subj = max(1, int(FRAC_SUBJ * n_subj_total))\n        keep_idx = rng.choice(n_subj_total, size=n_keep_subj, replace=False)\n        unique_subj = unique_subj[keep_idx]\n        print(f\"  -> using only {n_keep_subj} subjects ({FRAC_SUBJ*100:.1f}% of this shard)\")\n    # --------------------------------------------------\n\n    # shuffle subjects and split 70/10/20 (per shard)\n    rng.shuffle(unique_subj)\n    n_subj = len(unique_subj)\n    n_train_subj = int(0.7 * n_subj)\n    n_val_subj = int(0.1 * n_subj)\n\n    train_subj = set(unique_subj[:n_train_subj])\n    val_subj = set(unique_subj[n_train_subj:(n_train_subj + n_val_subj)])\n    test_subj = set(unique_subj[(n_train_subj + n_val_subj):])\n\n    # all mini-vols by subject\n    train_idx = [i for i, (s, _) in enumerate(ds.mini_index) if s in train_subj]\n    val_idx = [i for i, (s, _) in enumerate(ds.mini_index) if s in val_subj]\n    test_idx  = [i for i, (s, _) in enumerate(ds.mini_index) if s in test_subj]\n\n    # POS mini-vols: subject is positive AND block actually contains a positive slice\n    train_pos_idx = [i for i, (s, _) in enumerate(ds.mini_index)\n                     if (s in train_subj) and any_pos_mask[s] and block_has_pos[i]]\n    val_pos_idx = [i for i, (s, _) in enumerate(ds.mini_index)\n                     if (s in val_subj)   and any_pos_mask[s] and block_has_pos[i]]\n\n    print(\n        f\"  -> train mini-vols: {len(train_idx)}, \"\n        f\"val mini-vols: {len(val_idx)}, \"\n        f\"test mini-vols: {len(test_idx)}\"\n    )\n    print(\n        f\"  -> POS train mini-vols: {len(train_pos_idx)}, \"\n        f\"POS val mini-vols: {len(val_pos_idx)}\"\n    )\n\n    train_subsets.append(Subset(ds, train_idx))\n    val_subsets.append(Subset(ds, val_idx))\n    test_subsets.append(Subset(ds, test_idx))\n\n    train_pos_subsets.append(Subset(ds, train_pos_idx))\n    val_pos_subsets.append(Subset(ds, val_pos_idx))\n\n# final cross-shard train/val datasets\ntrain_dataset = ConcatDataset(train_subsets)\nval_dataset = ConcatDataset(val_subsets)\ntest_dataset = ConcatDataset(test_subsets)\ntrain_pos_dataset = ConcatDataset(train_pos_subsets)\nval_pos_dataset = ConcatDataset(val_pos_subsets)\n\nprint(\"Total train mini-vols:\", len(train_dataset))\nprint(\"Total val mini-vols:\", len(val_dataset))\nprint(\"Total test mini-vols:\", len(test_dataset))\nprint(\"Total POS train mini-vols:\", len(train_pos_dataset))\nprint(\"Total POS val mini-vols:\", len(val_pos_dataset))","metadata":{"papermill":{"duration":17.280988,"end_time":"2025-11-24T19:16:09.167636","exception":false,"start_time":"2025-11-24T19:15:51.886648","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"3a7740d8","cell_type":"code","source":"BATCH_SIZE = 64\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=4, # allows for parallelism on the CPU data loading side\n    pin_memory=True, # makes it faster to move batches from CPU to GPU (where we can run batches in parallel through model)\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True,\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True,\n)\n\ntrain_pos_loader = DataLoader(\n    train_pos_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True,\n)\n\nval_pos_loader = DataLoader(\n    val_pos_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True,\n)","metadata":{"papermill":{"duration":0.011493,"end_time":"2025-11-24T19:16:09.184242","exception":false,"start_time":"2025-11-24T19:16:09.172749","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"ca3d1dc9","cell_type":"code","source":"xb, y_any_b, y_where_b, subj_b = next(iter(train_loader))\nprint(\"x:\", xb.shape) # (B, 1, K, 128, 128)\nprint(\"y_any:\", y_any_b.shape) # (B,)\nprint(\"y_where:\", y_where_b.shape) # (B, 13)\nprint(\"subj:\", subj_b[:5])","metadata":{"papermill":{"duration":68.927555,"end_time":"2025-11-24T19:17:18.116459","exception":false,"start_time":"2025-11-24T19:16:09.188904","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"cfdd0956","cell_type":"markdown","source":"# **3D CNN**","metadata":{"papermill":{"duration":0.008784,"end_time":"2025-11-24T19:17:18.138753","exception":false,"start_time":"2025-11-24T19:17:18.129969","status":"completed"},"tags":[]}},{"id":"6a9b0d1b","cell_type":"code","source":"# run a 3D-CNN with three blocks of 2 convolutional layers followed by a max pooling layer\n# step 1 predicts if an aneurysm is present\n\nclass Step1_ConvModel(nn.Module):\n    def __init__(self,lr,wd):\n        super().__init__()\n        self.lr = lr\n        self.wd = wd\n        self.feature_extractor = nn.Sequential(\n            nn.Conv3d(1, 4, kernel_size=3, padding=1),\n            nn.BatchNorm3d(4),\n            nn.LeakyReLU(0.01),\n            nn.Conv3d(4, 8, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(8),\n            nn.LeakyReLU(0.01),\n            nn.MaxPool3d(2, 2), # output: 8 x 16 x 64 x 64\n\n            nn.Conv3d(8, 16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(16),\n            nn.LeakyReLU(0.01),\n            nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(32),\n            nn.LeakyReLU(0.01),\n            nn.MaxPool3d(2, 2), # output: 32 x 8 x 32 x 32\n\n            nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(64),\n            nn.LeakyReLU(0.01),\n            nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(128),\n            nn.LeakyReLU(0.01),\n            nn.MaxPool3d(2, 2), # output: 128 x 4 x 16 x 16\n\n            nn.AdaptiveAvgPool3d(1),\n            nn.Flatten())\n\n        # MLP head\n        self.classifier = nn.Sequential(\n            nn.Linear(128, 64), # output: 256 x 1\n            nn.LeakyReLU(0.01),\n            nn.Dropout(0.5),\n            nn.Linear(64, 32), # output: 128 x 1\n            nn.LeakyReLU(0.01),\n            nn.Linear(32, 1)) # 1 output layers\n\n    def forward(self,X):\n        # forward propagate x through network\n        features = self.feature_extractor(X)\n        return self.classifier(features)\n\n    def loss(self,logits,y, averaged = True):\n        # binary cross entropy loss\n        cross_entropy_loss = nn.BCEWithLogitsLoss(reduction = \"mean\" if averaged else \"none\")\n        return cross_entropy_loss(logits, y)\n\n    def predict(self,X, threshold = 0.5):\n        logits = self.forward(X)\n        probs = torch.sigmoid(logits)\n        preds = (probs > threshold).float()\n        return preds\n\n    def configure_optimizers(self):\n        # set up the Adam optimizer with default parameters and\n        # model's learning rate and weight decay\n        return optim.Adam(self.parameters(), weight_decay = self.wd, lr = self.lr)","metadata":{"papermill":{"duration":0.014798,"end_time":"2025-11-24T19:17:18.158225","exception":false,"start_time":"2025-11-24T19:17:18.143427","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"98620a18","cell_type":"code","source":"# run a 3D-CNN with three blocks of 2 convolutional layers followed by a max pooling layer\n# step 2 is conditional on the first step, it predicts the location of the aneurysm\n\nclass Step2_ConvModel(nn.Module):\n    def __init__(self,lr,wd, pretrained_cnn):\n        super().__init__()\n        self.lr = lr\n        self.wd = wd\n        self.feature_extractor = pretrained_cnn\n\n        self.classifier = nn.Sequential(\n            nn.Linear(128, 128), # output: 128 x 1\n            nn.LeakyReLU(0.01),\n            nn.Dropout(0.5),\n            nn.Linear(128, 64), # output: 64 x 1\n            nn.LeakyReLU(0.01),\n            nn.Linear(64, 13)) # 13 output layers\n\n    def forward(self,X):\n        # forward propagate x through network\n        features = self.feature_extractor(X)\n        return self.classifier(features)\n\n    def loss(self,logits, y, averaged = True):\n        # compute multi-label classificationcross-entropy loss between network output and true labels y\n        loss_per_entry = torch.clamp(logits, min = 0) - logits * y + torch.log1p(torch.exp(-torch.abs(logits))) #compute binary cross_entropy per entropy\n        return loss_per_entry.mean()\n\n    def predict(self,X, threshold = 0.2):\n        logits = self.forward(X)\n        probs = torch.sigmoid(logits)\n        preds = (probs > threshold).float()\n        return preds\n\n    def configure_optimizers(self):\n        # set up the Adam optimizer with default parameters and\n        # model's learning rate and weight decay\n        return optim.Adam(self.parameters(), weight_decay = self.wd, lr = self.lr)","metadata":{"papermill":{"duration":0.012038,"end_time":"2025-11-24T19:17:18.175023","exception":false,"start_time":"2025-11-24T19:17:18.162985","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"d60147f1","cell_type":"markdown","source":"# **Train Model**","metadata":{"papermill":{"duration":0.004545,"end_time":"2025-11-24T19:17:18.184182","exception":false,"start_time":"2025-11-24T19:17:18.179637","status":"completed"},"tags":[]}},{"id":"88b246f0","cell_type":"code","source":"def train_model(model, trainloader, valloader, num_epochs, opt, save_path, step1 = True):\n    train_loss, val_loss = [], []\n    device = next(model.parameters()).device # Get the device of the model\n\n    best_val_loss = float(\"inf\")\n    \n    for epoch in range(num_epochs):\n        # train\n        model.train()\n        running_loss, n_seen = 0.0, 0\n        for Xtr, ytr_any, ytr_loc, subj in trainloader:\n            if step1:\n                ytr = ytr_any.float().unsqueeze(1)\n            else:\n                ytr = ytr_loc\n\n            # Move data to the same device as the model\n            Xtr, ytr = Xtr.to(device), ytr.to(device)\n            \n            opt.zero_grad()\n            yhat_logit = model.forward(Xtr)\n            loss = model.loss(yhat_logit, ytr, averaged=True)  # mean over this batch\n            loss.backward()\n            opt.step()\n            bs = ytr.size(0) # batch size\n            running_loss += loss.item() * bs # just get sum for batch\n            n_seen += bs\n        train_loss.append(running_loss / max(1, n_seen))\n\n        # val\n        model.eval()\n        v_running, v_seen = 0.0, 0\n        with torch.no_grad():\n            for Xval, yval_any, yval_loc, subj in valloader:\n                if step1:\n                    yval = yval_any.float().unsqueeze(1)\n                else:\n                    yval = yval_loc\n\n                # Move data to the same device as the model\n                Xval, yval = Xval.to(device), yval.to(device)\n                \n                vloss = model.loss(model(Xval), yval, averaged=True)\n                bs = yval.size(0)\n                v_running += vloss.item() * bs\n                v_seen += bs\n        current_v_loss = v_running / max(1, v_seen)\n        \n        val_loss.append(current_v_loss)\n\n        if current_v_loss < best_val_loss:\n            best_val_loss = current_v_loss\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'val_loss': current_v_loss,\n            }, save_path)\n            print(f\" Saved new best model at epoch {epoch+1} with val_loss = {current_v_loss:.4f}\")\n        else:\n            print(f\" Completed epoch {epoch+1} with val_loss = {current_v_loss:.4f}\")\n        \n    return model,train_loss,val_loss","metadata":{"papermill":{"duration":0.01359,"end_time":"2025-11-24T19:17:18.202267","exception":false,"start_time":"2025-11-24T19:17:18.188677","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"db00cc26","cell_type":"code","source":"def plot_loss_curves(num_epochs,train_loss,val_loss):\n   plt.plot(torch.arange(num_epochs),train_loss, label=\"train_loss\")\n   plt.plot(torch.arange(num_epochs),val_loss, label=\"val_loss\")\n   plt.title(\"Training and Validation Loss Curves\")\n   plt.xlabel(\"Epoch\")\n   plt.ylabel(\"Loss\")\n   plt.legend()","metadata":{"papermill":{"duration":0.010281,"end_time":"2025-11-24T19:17:18.217292","exception":false,"start_time":"2025-11-24T19:17:18.207011","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"bb8f84e1","cell_type":"markdown","source":"# **Freeze CNN Layers for 2nd Step**","metadata":{"papermill":{"duration":0.004599,"end_time":"2025-11-24T19:17:18.226429","exception":false,"start_time":"2025-11-24T19:17:18.221830","status":"completed"},"tags":[]}},{"id":"0eb7eadf","cell_type":"code","source":"def freeze_all_but_last_block(model):\n    for p in model.feature_extractor.parameters():\n        p.requires_grad = False\n\n    # unfreeze the last layers\n    for name, p in model.feature_extractor.named_parameters():\n        if \"128\" in name:\n            p.requires_grad = True\n            print(\"Unfreezing:\", name)\n\ndef build_finetune_optimizer(model, lr, wd):\n    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n    return torch.optim.Adam(trainable_params, lr=lr, weight_decay=wd)","metadata":{"papermill":{"duration":0.010555,"end_time":"2025-11-24T19:17:18.241475","exception":false,"start_time":"2025-11-24T19:17:18.230920","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"f3684428","cell_type":"markdown","source":"# **Train**","metadata":{"papermill":{"duration":0.004471,"end_time":"2025-11-24T19:17:18.250544","exception":false,"start_time":"2025-11-24T19:17:18.246073","status":"completed"},"tags":[]}},{"id":"56a1c8a1","cell_type":"code","source":"# set hyperparameters\nlr = 1e-4\nwd = 1e-5\nnum_epochs = 6\n\n# define device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# define and train step 1 model\nstep1_cnn_model = Step1_ConvModel(lr, wd).to(device)\nstep1_cnn_model, step1_train_loss, step1_val_loss = train_model(step1_cnn_model, train_loader, val_loader, num_epochs,\n                                                                opt = step1_cnn_model.configure_optimizers(),\n                                                                save_path = \"best_model_step1.pt\", step1 = True)\n\n# plot validation and training loss curves\nplot_loss_curves(num_epochs, step1_train_loss, step1_val_loss)","metadata":{"papermill":{"duration":30340.037628,"end_time":"2025-11-25T03:42:58.292669","exception":false,"start_time":"2025-11-24T19:17:18.255041","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"6fd7602c","cell_type":"code","source":"# hyperparameters\nlr = 1e-4\nwd = 1e-5\nnum_epochs = 10\n\n# initialize step 2 model\nstep2_cnn_model = Step2_ConvModel(lr, wd, step1_cnn_model.feature_extractor).to(device)\n\n# freeze CNN except last block\nfreeze_all_but_last_block(step2_cnn_model)\n\n# build finetuned optimizer\nfinetuned_optimizer = build_finetune_optimizer(step2_cnn_model, lr = lr, wd = wd)\n\nstep2_cnn_model, step2_train_loss, step2_val_loss = train_model(step2_cnn_model, train_pos_loader, val_pos_loader, num_epochs,\n                                                                opt = finetuned_optimizer, step1 = False,\n                                                               save_path = \"best_model_step2.pt\")\n\n# plot validation and training loss curves\nplot_loss_curves(num_epochs, step2_train_loss, step2_val_loss)","metadata":{"papermill":{"duration":2940.913881,"end_time":"2025-11-25T04:31:59.226638","exception":false,"start_time":"2025-11-25T03:42:58.312757","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"49bb3d69","cell_type":"markdown","source":"# **Evaluate Model**","metadata":{"papermill":{"duration":0.007028,"end_time":"2025-11-25T04:31:59.240979","exception":false,"start_time":"2025-11-25T04:31:59.233951","status":"completed"},"tags":[]}},{"id":"9dd52faf","cell_type":"code","source":"def model_eval(step1_model, step2_model, testloader, aneurysm_threshold = 0.5, location_threshold = 0.2):\n    step1_model.eval()\n    step2_model.eval()\n    ys, probs_list, subj_list = [], [], [] # Use a list to store batches of test data\n\n    with torch.no_grad():\n        for tX, ty_any, ty_loc, tsubj in testloader:\n            tX, ty_any, ty_loc, tsubj = tX.to(device), ty_any.to(device), ty_loc.to(device), tsubj.to(device)\n            \n            # forward pass in step 1\n            step1_logits = step1_model.forward(tX)\n            step1_prob = torch.sigmoid(step1_logits).squeeze(1)\n\n            # fill out step 2 probs with 0s\n            batch_size = tX.size(0)\n            step2_dim = 13\n            step2_probs = torch.zeros(batch_size, step2_dim, device = device)\n\n            # which indices to run step 2\n            idxs = (step1_prob > aneurysm_threshold).nonzero(as_tuple = True)[0]\n\n            if len(idxs) > 0:\n                tX_selected = tX[idxs]\n                step2_logits = step2_model.forward(tX_selected)\n                step2_probs_selected = torch.sigmoid(step2_logits)\n\n                step2_probs[idxs] = step2_probs_selected   \n\n            # combine probs and ys\n            combined_probs = torch.cat((step2_probs, step1_prob.unsqueeze(1)), dim=1)\n            combined_ys = torch.cat((ty_loc, ty_any.unsqueeze(1)), dim = 1)\n            \n            # Store\n            ys.append(combined_ys.cpu().numpy())\n            probs_list.append(combined_probs.cpu().numpy())\n            subj_list.append(tsubj.cpu().numpy())\n            \n    ys = np.concatenate(ys, axis = 0)\n    probs = np.concatenate(probs_list, axis = 0)\n    subjects = np.concatenate(subj_list, axis = 0)\n\n    # subject level aggregation\n    from collections import defaultdict\n\n    probs_by_subj = defaultdict(list)\n    ys_by_subj = defaultdict(list)\n\n    # put y, probs into subject oriented list\n    for y, p, sid in zip(ys, probs, subjects):\n        probs_by_subj[int(sid)].append(p)\n        ys_by_subj[int(sid)].append(y)\n\n    final_probs_subj = {}\n    final_preds_subj = {}\n    final_labels_subj = {}\n\n    for sid in probs_by_subj.keys():\n        subj_probs = np.stack(probs_by_subj[sid], axis = 0)\n        subj_labels = np.stack(ys_by_subj[sid], axis = 0)\n\n        final_prob_vec = np.zeros(14)\n        final_pred_vec = np.zeros(14, dtype = int)\n        final_label_vec = subj_labels.max(axis = 0).astype(int)\n        \n        for j in range(14):\n            col_probs = subj_probs[:, j]\n\n            # select threshold\n            if j == 13:\n                thr = aneurysm_threshold\n            else:\n                thr = location_threshold\n\n            # apply max or average\n            if np.any(col_probs > thr):\n                final_prob = np.max(col_probs)\n            else:\n                final_prob = np.mean(col_probs)\n\n            final_prob_vec[j] = final_prob\n            final_pred_vec[j] = 1 if final_prob > 0.5 else 0\n\n        final_probs_subj[sid] = final_prob_vec\n        final_preds_subj[sid] = final_pred_vec\n        final_labels_subj[sid] = final_label_vec\n\n    # convert to arrays\n    subj_ids_sorted = sorted(final_preds_subj.keys())\n\n    probs_subj = np.stack([final_probs_subj[s] for s in subj_ids_sorted], axis = 0)\n    preds_subj = np.stack([final_preds_subj[s] for s in subj_ids_sorted], axis = 0)\n    ys_subj = np.stack([final_labels_subj[s] for s in subj_ids_sorted], axis = 0)\n    \n    print(\"****************************************************************************************\")\n    print(\"performance report\")\n\n    print(sklearn.metrics.classification_report(ys_subj, preds_subj, zero_division = 0))\n    \n    return ys_subj,preds_subj, probs_subj\n\ndef weighted_multiclass_roc_auc(Y_true, Y_prob, weights):\n    n_classes = Y_true.shape[1]\n    aucs = []\n    \n    for i in range(n_classes):\n        try:\n            auc = roc_auc_score(Y_true[:, i], Y_prob[:, i])\n        except ValueError:\n            auc = np.nan\n        aucs.append(auc)\n        \n    aucs = np.array(aucs)\n\n    valid = ~np.isnan(aucs)\n    weighted_auc = np.sum(weights[valid] * aucs[valid]) / np.sum(weights[valid])\n\n    return weighted_auc","metadata":{"papermill":{"duration":0.021705,"end_time":"2025-11-25T04:31:59.268847","exception":false,"start_time":"2025-11-25T04:31:59.247142","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"9b0df709","cell_type":"code","source":"weights = np.array([1/26]*13 + [.5])\n\n# load best models\ncheckpoint1 = torch.load(\"best_model_step1.pt\", map_location='cpu', weights_only = False)\ncheckpoint2 = torch.load(\"best_model_step2.pt\", map_location='cpu', weights_only = False)\n\nstep1_cnn_model.load_state_dict(checkpoint1['model_state_dict'])\nstep2_cnn_model.load_state_dict(checkpoint2['model_state_dict'])\n\n# get accuracy, classification report, weighted AUC\nys, preds, probs = model_eval(step1_cnn_model, step2_cnn_model, test_loader)\n\nweighted_auc = weighted_multiclass_roc_auc(ys, probs, weights)\nprint(f\"Weighted ROC AUC: {weighted_auc:.4f}\")","metadata":{"papermill":{"duration":1158.744245,"end_time":"2025-11-25T04:51:18.019180","exception":false,"start_time":"2025-11-25T04:31:59.274935","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}