{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":277597825,"sourceType":"kernelVersion"},{"sourceId":277597849,"sourceType":"kernelVersion"},{"sourceId":277597875,"sourceType":"kernelVersion"},{"sourceId":277597952,"sourceType":"kernelVersion"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":20822.412452,"end_time":"2025-11-25T22:28:30.003297","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-25T16:41:27.590845","version":"2.6.0"},"colab":{"provenance":[]}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0dd06f12","cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.metrics import roc_auc_score\nimport h5py","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":15.859469,"end_time":"2025-11-25T16:41:46.949334","exception":false,"start_time":"2025-11-25T16:41:31.089865","status":"completed"},"tags":[],"id":"0dd06f12","trusted":true},"outputs":[],"execution_count":null},{"id":"63ff267b","cell_type":"code","source":"ID_COL = 'SeriesInstanceUID'\n\nLABEL_COLS = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present',\n]\n\n# All tags (other than PixelData and SeriesInstanceUID) that may be in a test set dcm file\nDICOM_TAG_ALLOWLIST = [\n    'BitsAllocated',\n    'BitsStored',\n    'Columns',\n    'FrameOfReferenceUID',\n    'HighBit',\n    'ImageOrientationPatient',\n    'ImagePositionPatient',\n    'InstanceNumber',\n    'Modality',\n    'PatientID',\n    'PhotometricInterpretation',\n    'PixelRepresentation',\n    'PixelSpacing',\n    'PlanarConfiguration',\n    'RescaleIntercept',\n    'RescaleSlope',\n    'RescaleType',\n    'Rows',\n    'SOPClassUID',\n    'SOPInstanceUID',\n    'SamplesPerPixel',\n    'SliceThickness',\n    'SpacingBetweenSlices',\n    'StudyInstanceUID',\n    'TransferSyntaxUID',\n]","metadata":{"papermill":{"duration":0.009743,"end_time":"2025-11-25T16:41:46.962483","exception":false,"start_time":"2025-11-25T16:41:46.952740","status":"completed"},"tags":[],"id":"63ff267b","trusted":true},"outputs":[],"execution_count":null},{"id":"d0ca927f","cell_type":"code","source":"class MiniVolDataset(Dataset):\n    def __init__(self, h5_path, K=32, use_3d=True, return_id=False):\n        self.h5_path = h5_path\n        self.K = K\n        self.use_3d = use_3d\n        self.return_id = return_id\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        mini_index = [] # list of (subject_idx, slice_idx_array)\n\n        with h5py.File(h5_path, \"r\") as f:\n            z_len = f[\"z_len\"][:] \n            num_scans = len(z_len)\n\n            for s in range(num_scans):\n                Z = int(z_len[s])\n                if Z < K:\n                    continue # this subject contributes no mini-vols\n\n                # all slice indices in physical order (from preprocessing)\n                avail = np.arange(Z, dtype=np.int16)\n\n                # repeatedly carve out K indices spread across 'avail'\n                while len(avail) >= K:\n                    n = len(avail) # current number of remaining slices\n\n                    # positions in 0..n-1 roughly at quantiles:\n                    # floor((i+0.5) * n / K), i = 0,...,K-1\n                    pos = np.floor((np.arange(K) + 0.5) * n / K).astype(int)\n\n                    # get actual slice indices (already sorted because avail and pos are sorted)\n                    block = avail[pos] # shape (K,)\n\n                    # record this mini-volume definition\n                    mini_index.append((s, block.copy()))\n\n                    # remove those positions from 'avail' so they won't be reused\n                    avail = np.delete(avail, pos)\n\n        self.mini_index = mini_index\n\n        # HDF5 handles opened lazily per worker\n        self._file = None\n        self._x_grp = None\n        self._y_ds = None\n        self._uid_ds = None\n\n    def _ensure_open(self): # allows us to open file once per shard (so we don't need to reopen each time we index the dataset)\n        if self._file is None:\n            self._file = h5py.File(self.h5_path, \"r\")\n            self._x_grp = self._file[\"x\"]\n            self._y_ds  = self._file[\"y\"]\n            self._uid_ds = self._file.get(\"uid\", None)\n\n    def __len__(self):\n        return len(self.mini_index)\n\n    def __getitem__(self, idx):\n        self._ensure_open()\n\n        subj_idx, slice_idx = self.mini_index[idx]  # slice_idx: (K,)\n\n        # load ONLY the K slices we need; underlying dataset is ordered\n        dset = self._x_grp[str(subj_idx)] # shape (Z_s, 256, 256)\n        mini = dset[slice_idx] # shape (K, 256, 256), float16\n\n        x = torch.from_numpy(mini)\n        x = self.pool(x) # max pool to drop dimensions to (K, 128, 128)\n\n        if self.use_3d:\n            # (1, K, H, W) for 3D convs\n            x = x.unsqueeze(0)\n        x = x.float()\n\n        # labels: one per subject\n        y_np = self._y_ds[subj_idx]\n        y = torch.from_numpy(y_np.astype(\"int64\"))\n\n        if self.return_id:\n            return x, y, int(subj_idx)\n        else:\n            return x, y","metadata":{"papermill":{"duration":0.013652,"end_time":"2025-11-25T16:41:46.979210","exception":false,"start_time":"2025-11-25T16:41:46.965558","status":"completed"},"tags":[],"id":"d0ca927f","trusted":true},"outputs":[],"execution_count":null},{"id":"7ed6525a","cell_type":"code","source":"shard_dirs = [\n    \"preprocess-cnn-all-slices-shard-1\",\n    \"preprocess-cnn-all-slices-shard-2\",\n    \"preprocess-cnn-all-slices-shard-3\",\n    \"preprocess-cnn-all-slices-shard-4\",\n]\n\nshard_paths = [f\"/kaggle/input/{d}/dataset_shard_{i}_all_slices.h5\" for i, d in enumerate(shard_dirs)]\n\nper_shard_ds = [\n    MiniVolDataset(\n        h5_path=path,\n        K=32,\n        use_3d=True, # channel dim specified\n        return_id=True, # gives subject index within that shard\n    )\n    for path in shard_paths\n]\n\nfull_dataset = ConcatDataset(per_shard_ds)","metadata":{"papermill":{"duration":0.3855,"end_time":"2025-11-25T16:41:47.367705","exception":false,"start_time":"2025-11-25T16:41:46.982205","status":"completed"},"tags":[],"id":"7ed6525a","trusted":true},"outputs":[],"execution_count":null},{"id":"154ad678","cell_type":"code","source":"# Subject-level train/val split PER SHARD\nrng = np.random.default_rng(42)\n\ntrain_subsets = []\nval_subsets = []\ntest_subsets = []\n\nfor shard_id, ds in enumerate(per_shard_ds):\n    # all subject indices for this shard\n    subj_indices = np.array([s for (s, _) in ds.mini_index], dtype=int)\n    unique_subj = np.unique(subj_indices)\n\n    print(f\"Shard {shard_id}: {len(unique_subj)} subjects, {len(ds)} mini-volumes\")\n\n    # shuffle subjects and split 70/10/20 (per shard)\n    rng.shuffle(unique_subj)\n    n_subj = len(unique_subj)\n    n_train_subj = int(0.7 * n_subj)\n    n_val_subj = int(0.1 * n_subj)\n\n    train_subj = set(unique_subj[:n_train_subj])\n    val_subj = set(unique_subj[n_train_subj:(n_train_subj + n_val_subj)])\n    test_subj = set(unique_subj[(n_train_subj + n_val_subj):])\n\n    # dataset indices whose subject is in train vs val\n    train_idx = [i for i, (s, _) in enumerate(ds.mini_index) if s in train_subj]\n    val_idx = [i for i, (s, _) in enumerate(ds.mini_index) if s in val_subj]\n    test_idx = [i for i, (s, _) in enumerate(ds.mini_index) if s in test_subj]\n\n    print(\n        f\"  -> train mini-vols: {len(train_idx)}, \"\n        f\"val mini-vols: {len(val_idx)}, \"\n        f\"test mini-vols: {len(test_idx)}\"\n    )\n\n    train_subsets.append(Subset(ds, train_idx))\n    val_subsets.append(Subset(ds, val_idx))\n    test_subsets.append(Subset(ds, test_idx))\n\n# final cross-shard train/val datasets\ntrain_dataset = ConcatDataset(train_subsets)\nval_dataset = ConcatDataset(val_subsets)\ntest_dataset = ConcatDataset(test_subsets)\n\nprint(\"Total train mini-vols:\", len(train_dataset))\nprint(\"Total val mini-vols:\", len(val_dataset))\nprint(\"Total test mini-vols:\", len(test_dataset))","metadata":{"papermill":{"duration":0.024537,"end_time":"2025-11-25T16:41:47.395476","exception":false,"start_time":"2025-11-25T16:41:47.370939","status":"completed"},"tags":[],"id":"154ad678","outputId":"79d72cc1-c8f4-490e-da5c-37131c0da19e","trusted":true},"outputs":[],"execution_count":null},{"id":"ceabed71","cell_type":"code","source":"BATCH_SIZE = 64\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=4, # allows for parallelism on the CPU data loading side\n    pin_memory=True, #makes it faster to move batches from CPU to GPU (where we can run batches in parallel through model)\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True,\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True,\n)\n\n# check one batch\nxb, yb, subj_b = next(iter(train_loader))\nprint(\"Batch x shape:\", xb.shape) # (B, 1, 16, 256, 256)\nprint(\"Batch y shape:\", yb.shape) # (B, 14)\nprint(\"Batch subj_idx:\", subj_b[:5])","metadata":{"papermill":{"duration":66.23098,"end_time":"2025-11-25T16:42:53.630136","exception":false,"start_time":"2025-11-25T16:41:47.399156","status":"completed"},"tags":[],"id":"ceabed71","outputId":"e5b19967-c13a-4c63-f412-06d53ee64799","trusted":true},"outputs":[],"execution_count":null},{"id":"915af589","cell_type":"markdown","source":"# **3D CNN**","metadata":{"papermill":{"duration":0.008114,"end_time":"2025-11-25T16:42:53.646819","exception":false,"start_time":"2025-11-25T16:42:53.638705","status":"completed"},"tags":[],"id":"915af589"}},{"id":"70adab18","cell_type":"markdown","source":"code copied from RSNA Competition - C2","metadata":{"papermill":{"duration":0.00313,"end_time":"2025-11-25T16:42:53.655869","exception":false,"start_time":"2025-11-25T16:42:53.652739","status":"completed"},"tags":[],"id":"70adab18"}},{"id":"83c6e9d8","cell_type":"code","source":"# run a CNN with three blocks of 2 convolutional layers followed by a max pooling layer\n# treat depth of slices as channels\n\nclass ConvModel(nn.Module):\n    def __init__(self,lr,wd, weights):\n        super().__init__()\n        self.lr = lr\n        self.wd = wd\n        self.weights = weights\n        self.net = nn.Sequential(\n            nn.Conv3d(1, 4, kernel_size=3, padding=1),\n            nn.BatchNorm3d(4),\n            nn.LeakyReLU(0.01),\n            nn.Conv3d(4, 8, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(8),\n            nn.LeakyReLU(0.01),\n            nn.MaxPool3d(2, 2), # output: 8 x 16 x 64 x 64\n\n            nn.Conv3d(8, 16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(16),\n            nn.LeakyReLU(0.01),\n            nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(32),\n            nn.LeakyReLU(0.01),\n            nn.MaxPool3d(2, 2), # output: 32 x 8 x 32 x 32\n\n            nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(64),\n            nn.LeakyReLU(0.01),\n            nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm3d(128),\n            nn.LeakyReLU(0.01),\n            nn.MaxPool3d(2, 2), # output: 128 x 4 x 16 x 16\n\n            nn.AdaptiveAvgPool3d(1),\n            nn.Flatten(),\n            nn.Linear(128, 256), # output: 256 x 1\n            nn.LeakyReLU(0.01),\n            nn.Dropout(0.5),\n            nn.Linear(256, 128), # output: 128 x 1\n            nn.LeakyReLU(0.01),\n            nn.Linear(128, 14)) # 14 output layers\n\n    def forward(self,X):\n        # forward propagate x through network\n        return self.net(X)\n\n    def loss(self,logits,y,averaged=True):\n        # compute multi-label classificationcross-entropy loss between network output and true labels y\n        weights = torch.tensor(self.weights, dtype=logits.dtype, device=logits.device) # ensure weights are a tensor\n\n        # numerically stable loss computation, logits = max(logits, 0) - logits * y + log(1 + exp(-abs(logits)))\n        loss_per_entry = torch.clamp(logits, min = 0) - logits * y + torch.log1p(torch.exp(-torch.abs(logits))) #compute binary cross_entropy per entropy\n        loss_per_entry = loss_per_entry * weights # apply weights\n        return loss_per_entry.mean()\n\n    def predict(self,X, threshold = 0.5):\n        logits = self.forward(X)\n        probs = torch.sigmoid(logits)\n        preds = (probs > threshold).float()\n        return preds\n\n    def configure_optimizers(self):\n        # set up the Adam optimizer with default parameters and\n        # model's learning rate and weight decay\n        return optim.Adam(self.parameters(), weight_decay = self.wd, lr = self.lr)","metadata":{"papermill":{"duration":0.01428,"end_time":"2025-11-25T16:42:53.673254","exception":false,"start_time":"2025-11-25T16:42:53.658974","status":"completed"},"tags":[],"id":"83c6e9d8","trusted":true},"outputs":[],"execution_count":null},{"id":"4255cb56","cell_type":"markdown","source":"# **Train Model**","metadata":{"papermill":{"duration":0.00295,"end_time":"2025-11-25T16:42:53.679232","exception":false,"start_time":"2025-11-25T16:42:53.676282","status":"completed"},"tags":[],"id":"4255cb56"}},{"id":"ada6c13b","cell_type":"code","source":"def train_model(model,trainloader,valloader,num_epochs):\n    train_loss, val_loss = [], []\n    opt = model.configure_optimizers()\n    device = next(model.parameters()).device # Get the device of the model\n\n    best_val_loss = float(\"inf\")\n\n    for epoch in range(num_epochs):\n        # train\n        model.train()\n        running_loss, n_seen = 0.0, 0\n        for Xtr, ytr, subj in trainloader:\n            Xtr, ytr = Xtr.to(device), ytr.to(device) # Move data to the same device as the model\n            opt.zero_grad()\n            yhat_logit = model.forward(Xtr)\n            loss = model.loss(yhat_logit, ytr, averaged=True)  # mean over this batch\n            loss.backward()\n            opt.step()\n            bs = ytr.size(0) # batch size\n            running_loss += loss.item() * bs # just get sum for batch\n            n_seen += bs\n        train_loss.append(running_loss / max(1, n_seen))\n\n        # val\n        model.eval()\n        v_running, v_seen = 0.0, 0\n        with torch.no_grad():\n            for Xval, yval, subj in valloader:\n                Xval, yval = Xval.to(device), yval.to(device) # Move data to the same device as the model\n                vloss = model.loss(model(Xval), yval, averaged=True)\n                bs = yval.size(0)\n                v_running += vloss.item() * bs\n                v_seen += bs\n        current_v_loss = v_running / max(1, v_seen)\n\n        val_loss.append(current_v_loss)\n\n        if current_v_loss < best_val_loss:\n            best_val_loss = current_v_loss\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'val_loss': current_v_loss,\n            }, \"best_model.pt\")\n            print(f\" Saved new best model at epoch {epoch+1} with val_loss = {current_v_loss:.4f}\")\n        else:\n            print(f\" Completed epoch {epoch+1} with val_loss = {current_v_loss:.4f}\")\n\n    return model,train_loss,val_loss","metadata":{"papermill":{"duration":0.011784,"end_time":"2025-11-25T16:42:53.693941","exception":false,"start_time":"2025-11-25T16:42:53.682157","status":"completed"},"tags":[],"id":"ada6c13b","trusted":true},"outputs":[],"execution_count":null},{"id":"27fc28dc","cell_type":"code","source":"def plot_loss_curves(num_epochs,train_loss,val_loss):\n   plt.plot(torch.arange(num_epochs),train_loss, label=\"train_loss\")\n   plt.plot(torch.arange(num_epochs),val_loss, label=\"val_loss\")\n   plt.title(\"Training and Validation Loss Curves\")\n   plt.xlabel(\"Epoch\")\n   plt.ylabel(\"Loss\")\n   plt.legend()","metadata":{"papermill":{"duration":0.008258,"end_time":"2025-11-25T16:42:53.705176","exception":false,"start_time":"2025-11-25T16:42:53.696918","status":"completed"},"tags":[],"id":"27fc28dc","trusted":true},"outputs":[],"execution_count":null},{"id":"af4d44bc","cell_type":"code","source":"# set hyperparameters\nlr = 1e-4\nwd = 5e-4\nnum_epochs = 5\n\nweights = np.array([1/26]*13 + [.5])\n\n# define model and device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncnn_model = ConvModel(lr, wd, weights).to(device)\n\n# train model\ncnn_model, train_loss, val_loss = train_model(cnn_model, train_loader, val_loader, num_epochs)\n\n# plot validation and training loss curves\nplot_loss_curves(num_epochs, train_loss, val_loss)","metadata":{"papermill":{"duration":19758.311995,"end_time":"2025-11-25T22:12:12.020139","exception":false,"start_time":"2025-11-25T16:42:53.708144","status":"completed"},"tags":[],"id":"af4d44bc","outputId":"0ae72507-7db4-4737-dea3-5c4c3a132595","trusted":true},"outputs":[],"execution_count":null},{"id":"9773b971","cell_type":"code","source":"def model_eval(model, testloader, aneurysm_threshold = 0.5, location_threshold = 0.2):\n    model.eval()\n    ys, probs_list, subj_list = [], [], [] # Use a list to store batches of test data\n\n    with torch.no_grad():\n        for tX, ty, tsubj in testloader:\n            tX, ty, tsubj = tX.to(device), ty.to(device), tsubj.to(device)\n\n            # forward pass\n            logits = model.forward(tX)\n            prob = torch.sigmoid(logits)\n\n            # Store\n            ys.append(ty.detach().cpu().numpy())\n            probs_list.append(prob.detach().cpu().numpy())\n            subj_list.append(tsubj.cpu().numpy())\n\n    ys = np.concatenate(ys, axis = 0)\n    probs = np.concatenate(probs_list, axis = 0)\n    subjects = np.concatenate(subj_list, axis = 0)\n\n    # subject level aggregation\n    from collections import defaultdict\n\n    probs_by_subj = defaultdict(list)\n    ys_by_subj = defaultdict(list)\n\n    # put y, probs into subject oriented list\n    for y, p, sid in zip(ys, probs, subjects):\n        probs_by_subj[int(sid)].append(p)\n        ys_by_subj[int(sid)].append(y)\n\n    final_probs_subj = {}\n    final_preds_subj = {}\n    final_labels_subj = {}\n\n    for sid in probs_by_subj.keys():\n        subj_probs = np.stack(probs_by_subj[sid], axis = 0)\n        subj_labels = np.stack(ys_by_subj[sid], axis = 0)\n\n        final_prob_vec = np.zeros(14)\n        final_pred_vec = np.zeros(14, dtype = int)\n        final_label_vec = subj_labels.max(axis = 0).astype(int)\n\n        for j in range(14):\n            col_probs = subj_probs[:, j]\n\n            # select threshold\n            if j == 13:\n                thr = aneurysm_threshold\n            else:\n                thr = location_threshold\n\n            # apply max or average\n            if np.any(col_probs > thr):\n                final_prob = np.max(col_probs)\n            else:\n                final_prob = np.mean(col_probs)\n\n            final_prob_vec[j] = final_prob\n            final_pred_vec[j] = 1 if final_prob > 0.5 else 0\n\n        final_probs_subj[sid] = final_prob_vec\n        final_preds_subj[sid] = final_pred_vec\n        final_labels_subj[sid] = final_label_vec\n\n    # convert to arrays\n    subj_ids_sorted = sorted(final_preds_subj.keys())\n\n    probs_subj = np.stack([final_probs_subj[s] for s in subj_ids_sorted], axis = 0)\n    preds_subj = np.stack([final_preds_subj[s] for s in subj_ids_sorted], axis = 0)\n    ys_subj = np.stack([final_labels_subj[s] for s in subj_ids_sorted], axis = 0)\n\n    print(\"****************************************************************************************\")\n    print(\"performance report\")\n\n    print(sklearn.metrics.classification_report(ys_subj, preds_subj, zero_division = 0))\n\n    return ys_subj,preds_subj, probs_subj\n\ndef weighted_multiclass_roc_auc(Y_true, Y_prob, weights):\n    n_classes = Y_true.shape[1]\n    aucs = []\n\n    for i in range(n_classes):\n        try:\n            auc = roc_auc_score(Y_true[:, i], Y_prob[:, i])\n        except ValueError:\n            auc = np.nan\n        aucs.append(auc)\n\n    aucs = np.array(aucs)\n\n    valid = ~np.isnan(aucs)\n    weighted_auc = np.sum(weights[valid] * aucs[valid]) / np.sum(weights[valid])\n\n    return weighted_auc","metadata":{"papermill":{"duration":0.016599,"end_time":"2025-11-25T22:12:12.040723","exception":false,"start_time":"2025-11-25T22:12:12.024124","status":"completed"},"tags":[],"id":"9773b971","trusted":true},"outputs":[],"execution_count":null},{"id":"28efa68f","cell_type":"code","source":"# get best model\ncheckpoint = torch.load(\"best_model.pt\", map_location='cpu', weights_only=False)\ncnn_model.load_state_dict(checkpoint['model_state_dict'])\n\n# get accuracy, classification report, weighted AUC\nys, preds, probs = model_eval(cnn_model, test_loader)\n\nweighted_auc = weighted_multiclass_roc_auc(ys, probs, weights)\nprint(f\"Weighted ROC AUC: {weighted_auc:.4f}\")","metadata":{"papermill":{"duration":974.806045,"end_time":"2025-11-25T22:28:26.850664","exception":false,"start_time":"2025-11-25T22:12:12.044619","status":"completed"},"tags":[],"id":"28efa68f","outputId":"e741972b-85f9-44a3-f126-0142cc9d3ffc","trusted":true},"outputs":[],"execution_count":null}]}